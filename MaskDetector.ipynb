{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avJv1-HjzLFB",
        "outputId": "47e8ad3a-6fcd-4ed2-f248-9183265201c0"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "#Function to load, preprocess, and return preprocessed image\n",
        "def load_preprocess_img(path):\n",
        "  #load and convert to numpy\n",
        "  image = load_img(path, target_size=(224, 224))\n",
        "  image = img_to_array(image)\n",
        "  #preprocessing - specific to mobilenetv2\n",
        "  image = preprocess_input(image)\n",
        "  return image\n",
        "\n",
        "#LOAD DATASET\n",
        "IMAGES = '/content/drive/MyDrive/FaceMaskDetector/images'    #path to images\n",
        "CATEGORIES = ['with_mask', 'without_mask', 'mask_weared_incorrect'] #categories of dataset\n",
        "DATA_SIZE = [1250, 1250, 2994] #number of images to load for each category\n",
        "\n",
        "data = []\n",
        "target = []\n",
        "\n",
        "#PREPROCESS\n",
        "for i in range(len(CATEGORIES)):\n",
        "  category = CATEGORIES[i]\n",
        "  print(f'Loading {category} images')\n",
        "  category_path = os.path.join(IMAGES, category)\n",
        "  for image in os.listdir(category_path)[:DATA_SIZE[i]]:\n",
        "    image = load_preprocess_img(os.path.join(category_path, image))\n",
        "    data.append(image)\n",
        "    target.append(category)\n",
        "\n",
        "\n",
        "data = np.array(data)\n",
        "target = np.array(target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPHu4JpqGYHG",
        "outputId": "6f9b21c7-7a04-41a0-a0c8-566d43d8312e"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "#ENCODE TARGET VALUES\n",
        "le = LabelEncoder()\n",
        "target = le.fit_transform(target)\n",
        "\n",
        "le.classes_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "B4MyQDzwUuNF"
      },
      "outputs": [],
      "source": [
        "#TRAIN-VALIDATION-TEST SPLIT\n",
        "from sklearn.model_selection import train_test_split\n",
        "#get train data\n",
        "X_train, X_temp, Y_train, Y_temp = train_test_split(data, target, test_size=0.4, random_state = 4001, stratify=target)\n",
        "#get validation and test data\n",
        "X_validate, X_test, Y_validate, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, random_state = 4001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmZJYHZnY8Y5",
        "outputId": "d3036045-120a-4542-e9e1-05438853aa2a"
      },
      "outputs": [],
      "source": [
        "#CONFIGURE MOBILENETV2\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "mobile = MobileNetV2(\n",
        "    weights='imagenet', #use pretrained weights from imagenet dataset\n",
        "    include_top = False,\n",
        "    input_tensor=Input(shape=(224, 224, 3))\n",
        ")\n",
        "#Original mobilenet model\n",
        "mobile.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqExYE-wsfDS",
        "outputId": "a779d793-0cc5-4e82-df98-a8d4e48b5ab6"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "outputLayer = mobile.output\n",
        "\n",
        "#add pooling layer to downsample output of mobilenet\n",
        "outputLayer = AveragePooling2D(pool_size=(7, 7))(outputLayer)\n",
        "#convert output of pooling layer into linear vector\n",
        "outputLayer = Flatten(name=\"flatten\")(outputLayer)\n",
        "#add hidden layer with 248 neurons\n",
        "outputLayer = Dense(248, activation=\"relu\")(outputLayer)\n",
        "#add dropout layer to nullify output of previous layer to prevent overfitting\n",
        "outputLayer = Dropout(0.5)(outputLayer)\n",
        "#final layer for output consisting of 3 neurons for 3 classes -> masked, unmasked, improper mask\n",
        "outputLayer = Dense(3, activation=\"softmax\")(outputLayer)\n",
        "\n",
        "model = Model(inputs=mobile.input, outputs=outputLayer)\n",
        "\n",
        "#Preserve imagenet weights from original mobilenet, only newly added layer weights will be updated\n",
        "for layer in mobile.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "#COMPILE MODEL\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.0001), \n",
        "    loss='sparse_categorical_crossentropy', \n",
        "    metrics=['accuracy']\n",
        "    )\n",
        "#Modified model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02YCd43rjivm",
        "outputId": "963dcb6a-bc5c-43d9-cbda-e69e96c20073"
      },
      "outputs": [],
      "source": [
        "#TRAIN MODEL\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "#use image data generator to break training data into batches\n",
        "idg = ImageDataGenerator()\n",
        "\n",
        "EPOCHS = 20\n",
        "fitting_data = model.fit(\n",
        "    idg.flow(X_train, Y_train, batch_size=32),\n",
        "    validation_data=(X_validate, Y_validate),\n",
        "    epochs = EPOCHS,\n",
        "    verbose = 2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "P6qvQdIA-FPe",
        "outputId": "1273790a-a54b-42e4-a810-08aed4e132a9"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(121)\n",
        "plt.plot(fitting_data.history[\"accuracy\"], label=\"Training accuracy\")\n",
        "plt.plot(fitting_data.history[\"val_accuracy\"], label=\"Value accuracy\")\n",
        "plt.title(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.subplot(122)\n",
        "plt.plot(fitting_data.history[\"loss\"], label=\"Training loss\")\n",
        "plt.plot(fitting_data.history[\"val_loss\"], label=\"Value loss\")\n",
        "plt.title(\"Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig(\"plot-model1.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9aMJbPPvo41x"
      },
      "outputs": [],
      "source": [
        "#Export model for future use\n",
        "model.save('mask_detector.model', save_format='h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meWzGoX35Kdf",
        "outputId": "a0612cdf-e4fe-44ca-c8c1-af741d8cbd5a"
      },
      "outputs": [],
      "source": [
        "#ANALYZE ACCURACY\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#Predict target values of test data\n",
        "pred = model.predict(X_test, batch_size=32)\n",
        "\n",
        "#Set prediction to class with highest probability\n",
        "pred = np.argmax(pred, axis=1)\n",
        "print(classification_report(Y_test.tolist(), pred.tolist(), target_names=le.classes_))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "MaskDetector.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
